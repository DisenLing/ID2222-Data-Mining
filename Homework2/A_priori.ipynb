{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Homework2-Discovery of Frequent Itemsets and Association Rules \n",
    "By group 29:Disen Ling,Zhenghong Xiao\n",
    "\n",
    "In this assignment we need to solve the following problems:\n",
    "\n",
    "1. Finding frequent itemsets with support at least s;\n",
    "2. Generating association rules with confidence at least c from the itemsets found in the first step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Exercise 1\n",
    "\n",
    "You are to solve the first sub-problem: to implement the A-Priori algorithm for finding frequent itemsets with support at least s in a dataset of sales transactions. Remind that support of an itemset is the number of transactions containing the itemset. To test and evaluate your implementation, write a program that uses your A-Priori algorithm implementation to discover frequent itemsets with support at least s in a given dataset of sales transactions which includes generated transactions (baskets) of hashed items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# The itertools library is used to combine items to form candidate item sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A_priori():\n",
    "    def __init__(self, threshold = 0.01, k = 3):\n",
    "        self.threshold = threshold # at least 1% of frequency --- frequent\n",
    "        self.k = k # the max size of the item set ([1,2,3]-3)\n",
    "        self.min_nr_transactions = None # number of transactions to define frequent\n",
    "\n",
    "    def read_dataset(self):\n",
    "        transactions_dic = {} # build a dict to store key-value pairs (item-transaction)\n",
    "        nr_transactions = 0 # number of transations which will be used in calculate support\n",
    "        # read the dataset and store the data in transactions_dic \n",
    "        with open(\"data/T10I4D100K.dat\", 'r') as file:\n",
    "            for i, line in enumerate(file):\n",
    "                nr_transactions += 1\n",
    "                # get the items in one transaction\n",
    "                transaction = [int(num) for num in line.strip().split(' ')]\n",
    "                for item in transaction:\n",
    "                # check if the item is already in the key-value pairs \n",
    "                    if item in transactions_dic.keys():\n",
    "                        transactions_dic[item].append(i)\n",
    "                    else:\n",
    "                        transactions_dic[item] = [i]\n",
    "        self.min_nr_transactions = nr_transactions * self.threshold\n",
    "        # the minimum number of transactions a frequent item should have\n",
    "        print(\"The transaction times threshold: \", self.min_nr_transactions)\n",
    "        return transactions_dic\n",
    "    \n",
    "    # get the original frequent items like {[1] [2] [3]}\n",
    "    def get_original_frequent_items(self, transactions_dic):\n",
    "        original_frequent_items = {}\n",
    "        for item in transactions_dic.keys():\n",
    "            # check if the frequence is above the minimum frequence 1%\n",
    "            if len(transactions_dic[item]) >= self.min_nr_transactions:\n",
    "                # if so, add this item to the original frequent items\n",
    "                original_frequent_items[item] = transactions_dic[item]\n",
    "        print(\"Amount of frequent items: \", len(original_frequent_items))\n",
    "        return original_frequent_items\n",
    "\n",
    "    # use the current frequent item sets to generate the candidate frequent item sets for next filter\n",
    "    def generate_candidates(self, original_frequent_items, frequent_items, factor):\n",
    "        # the first filter from original frequent items to frequent item sets which have 2 items\n",
    "        if factor == 2:\n",
    "            candidates = list(itertools.combinations(original_frequent_items.keys(), factor))\n",
    "        else:\n",
    "            # get all the items in the frequent item sets and combine them based on the combination factor\n",
    "            # [1,2] [2,3] [3,4] - 1,2,3,4 - [1,2,3] [2,3,4]\n",
    "            candidates = set()\n",
    "            for items in list(frequent_items.keys()):\n",
    "                for item in items:\n",
    "                    candidates.add(item)\n",
    "            candidates = list(itertools.combinations(candidates, factor))\n",
    "        return candidates\n",
    "    \n",
    "    # check if the candidates lists we generate are frequent\n",
    "    def check_candidates(self, candidates, original_frequent_items):\n",
    "        result = {} # the dic which is same to the original frequent items\n",
    "        # pair - transactions\n",
    "        for candidate in candidates:\n",
    "                for i in range(0,len(candidate)):\n",
    "                    if i == 0:\n",
    "                        # initialize the interasection set\n",
    "                        Interasection = set(original_frequent_items[candidate[i]])\n",
    "                    # the interasection set is the set shows which transactions contains the candidate pait\n",
    "                    Interasection = set.intersection(set(original_frequent_items[candidate[i]]),Interasection)\n",
    "                if len(Interasection) >= self.min_nr_transactions:\n",
    "                # check if this candidate is frequent\n",
    "                    result[candidate] = Interasection\n",
    "                    # the result is a map which contains frequent sets -- transactions\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Exercise 2\n",
    "\n",
    "Optional task for extra bonus: Solve the second sub-problem, i.e., develop and implement an algorithm for generating association rules between frequent itemsets discovered by using the A-Priori algorithm in a dataset of sales transactions. The rules must have support at least s and confidence at least c, where s and c are given as input parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assosiate_rule():\n",
    "    def __init__(self, confidence = 0.5):\n",
    "        self.confidence = confidence # the confidence of assosiate-rule\n",
    "\n",
    "    def assosiate(self, frequent_items, original_frequent_items):\n",
    "        associations = [] # the association implements are stored in this list\n",
    "        combinations = [] # combinations for frequent item pairs ([1,2,3] - [1,2] [1,3][2,3])\n",
    "        items = frequent_items.keys() # item paris \n",
    "        for item in items:\n",
    "            combinations.append(list(itertools.combinations(item, len(item) - 1)))\n",
    "        \n",
    "        # generate the X set and Y set which have the implement X --> Y\n",
    "        for idx, item in enumerate(items):\n",
    "            for combination in combinations[idx]:\n",
    "                # the assosiate item: [2,3] -> [1,2,3] so [1] is the assosiate item\n",
    "                assosiate_item = set(item) - set(combination)\n",
    "                for i in range(0,len(item)):\n",
    "                    if i == 0:\n",
    "                        Interasection1 = set(original_frequent_items[item[i]])\n",
    "                    Interasection1 = set.intersection(set(original_frequent_items[item[i]]),Interasection1)\n",
    "                Numerator = len(Interasection1)\n",
    "                # the frequence of the Y set (Support)\n",
    "                for i in range(0,len(combination)):\n",
    "                    if i == 0:\n",
    "                        Interasection2 = set(original_frequent_items[combination[i]])\n",
    "                    Interasection2 = set.intersection(set(original_frequent_items[combination[i]]),Interasection2)\n",
    "                Denominator = len(Interasection2)\n",
    "                # the frequence of the X set\n",
    "                confidence = Numerator/Denominator # calculate the confidence\n",
    "                if confidence >= self.confidence:\n",
    "                    associations.append(str(combination)+\"---→\"+str(assosiate_item)+\" : \"+str(confidence))\n",
    "        return associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transaction times threshold:  1000.0\n",
      "Amount of frequent items:  375\n",
      "Filter stage:  2\n",
      "(704,)---→{825} : 0.6142697881828316\n",
      "(704,)---→{39} : 0.617056856187291\n",
      "(227,)---→{390} : 0.577007700770077\n",
      "Frequent pairs:  (368, 682) Times:  1193\n",
      "Frequent pairs:  (368, 829) Times:  1194\n",
      "Frequent pairs:  (825, 39) Times:  1187\n",
      "Frequent pairs:  (825, 704) Times:  1102\n",
      "Frequent pairs:  (39, 704) Times:  1107\n",
      "Frequent pairs:  (227, 390) Times:  1049\n",
      "Frequent pairs:  (390, 722) Times:  1042\n",
      "Frequent pairs:  (217, 346) Times:  1336\n",
      "Frequent pairs:  (789, 829) Times:  1194\n",
      "Filter stage:  3\n",
      "(704, 39)---→{825} : 0.9349593495934959\n",
      "(704, 825)---→{39} : 0.9392014519056261\n",
      "(39, 825)---→{704} : 0.8719460825610783\n",
      "Frequent pairs:  (704, 39, 825) Times:  1035\n"
     ]
    }
   ],
   "source": [
    "k = 3 # Maximum size of association k-itemset\n",
    "a_priori = A_priori()\n",
    "assosiate_rule = Assosiate_rule()\n",
    "# get the dataset dict with key-value pairs (item-transactions)\n",
    "transactions_dic = a_priori.read_dataset()\n",
    "# get the first filter\n",
    "original_frequent_items = a_priori.get_original_frequent_items(transactions_dic)\n",
    "frequent_items = original_frequent_items\n",
    "\n",
    "# 2nd to kth filter\n",
    "for factor in range(2,k+1):\n",
    "    print(\"Filter stage: \", factor)\n",
    "    # get the frequent item set candidates\n",
    "    candidates = a_priori.generate_candidates(original_frequent_items, frequent_items, factor)\n",
    "    # check all the candidates and generate the result dict\n",
    "    frequent_items = a_priori.check_candidates(candidates, original_frequent_items)\n",
    "    # check the assosiation implements based on the frequent item sets\n",
    "    assosiations = assosiate_rule.assosiate(frequent_items, original_frequent_items)\n",
    "    # print the assosiation implements\n",
    "    print(*assosiations,sep = \"\\n\")\n",
    "    for key in frequent_items.keys():\n",
    "        print(\"Frequent pairs: \", key, \"Times: \", len(frequent_items[key]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25e659c40a44c2228aa98bd7e72a4093c6d7fe0379c35a3e6513719385e9cc8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
